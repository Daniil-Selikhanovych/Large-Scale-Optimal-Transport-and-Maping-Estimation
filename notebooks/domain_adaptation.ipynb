{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies\n",
    "First, you may need to install \n",
    "* NumPy - `pip install numpy`,\n",
    "* Matplotlib - `pip install matplotlib`,\n",
    "* PyTorch - `pip install torch torchvision`.\n",
    "\n",
    "Then you should be able to import all required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import MNIST, USPS\n",
    "from torch.utils.data import ConcatDataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import MultiStepLR, ExponentialLR\n",
    "from torch.distributions import MultivariateNormal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add parent directory to path to access sibling modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport neural_ot.data_loading, neural_ot.model, neural_ot.train\n",
    "from neural_ot.data_loading import ZipLoader\n",
    "from neural_ot.model import NeuralOT, Unflatten, Vector\n",
    "from neural_ot.train import train\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables\n",
    "First, we set `DEVICE` and `IS_CUDA` global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "    IS_CUDA = True\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    IS_CUDA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we download MNIST and USPS datasets using `torchvision.datasets`. We normalize intensities from the default interval $[0, 1]$ to the interval $[-1, 1]$ via linear transformation $I' = (I - 0.5) / 0.5$ (as it was done in the original paper). Also for the generative modeling task we concatenate train and test sets to the single dataset, held in global variable `mnist`. The same is done with `usps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = 16, 16\n",
    "mnist_tr = transforms.Compose([transforms.Resize((h, w)),\n",
    "                               transforms.ToTensor(), \n",
    "                               transforms.Normalize([.5], [.5]),\n",
    "                               ])\n",
    "usps_tr  = transforms.Compose([transforms.ToTensor(), \n",
    "                               transforms.Normalize([.5], [.5]),\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to study MNIST $\\to$ USPS mapping, just uncomment the lines below. They determine, which dataset is the source distribution and which is the target one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = MNIST('data/mnist', download=True, transform=mnist_tr, train=True)\n",
    "mnist_test = MNIST('data/mnist', download=True, transform=mnist_tr, train=False)\n",
    "mnist = ConcatDataset([mnist_train, mnist_test])\n",
    "\n",
    "usps_train = USPS('data/usps', download=True, transform=usps_tr, train=True)\n",
    "usps_test = USPS('data/usps', download=True, transform=usps_tr, train=False)\n",
    "usps = ConcatDataset([usps_train, usps_test])\n",
    "\n",
    "source = usps\n",
    "target = mnist\n",
    "\n",
    "# # We can swap the source and the target\n",
    "# source = mnist\n",
    "# target = usps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 300\n",
    "N_BATCHES_PER_EPOCH = 10\n",
    "N_WORKERS = 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_loader = ZipLoader(source, target, batch_size=BATCH_SIZE, n_batches=N_BATCHES_PER_EPOCH, \n",
    "                          pin_memory=IS_CUDA, return_idx=True, num_workers=N_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x_idx, x), (y_idx, y) in paired_loader:\n",
    "    print(x_idx.shape, x.shape, y_idx.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y[0, 0].numpy(), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We parametrized the $u$ and $v$ functions as `Vector` objects as they were used in the original article. Nevertheless, one can use neural networks to treat $u$ and $v$ as vectors. In this case don't forget to uncomment corresponding lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parametrization via neural network\n",
    "# source_dual_net = nn.Sequential(\n",
    "#     nn.Flatten(),\n",
    "#     nn.Linear(h * w, 1024),\n",
    "#     nn.ReLU(),\n",
    "#     nn.BatchNorm1d(1024),\n",
    "#     nn.Linear(1024, 1024),\n",
    "#     nn.ReLU(),\n",
    "#     nn.BatchNorm1d(1024),\n",
    "#     nn.Linear(1024, 1),\n",
    "#     nn.Flatten(start_dim=0)\n",
    "# )\n",
    "\n",
    "## Parametrization via vector\n",
    "source_dual_net = Vector(initial=1e-2 * torch.randn(len(source)))\n",
    "\n",
    "## Parametrization via neural network\n",
    "# target_dual_net = nn.Sequential(\n",
    "#     nn.Flatten(),\n",
    "#     nn.Linear(h * w, 1024),\n",
    "#     nn.ReLU(),\n",
    "#     nn.BatchNorm1d(1024),\n",
    "#     nn.Linear(1024, 1024),\n",
    "#     nn.ReLU(),\n",
    "#     nn.BatchNorm1d(1024),\n",
    "#     nn.Linear(1024, 1),\n",
    "#     nn.Flatten(start_dim=0)\n",
    "# )\n",
    "\n",
    "## Parametrization via vector\n",
    "target_dual_net = Vector(initial=1e-2 * torch.randn(len(target)))\n",
    "\n",
    "source_to_target_net = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(h * w, 200),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(200),\n",
    "    nn.Linear(200, 500),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(500),\n",
    "    nn.Linear(500, h * w),\n",
    "    Unflatten(h, w),\n",
    "    nn.Tanh()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ot = torch.load('generative_model.pth')\n",
    "# ot = NeuralOT(source_dual_net, target_dual_net, source_to_target_net, \n",
    "#               regularization_mode='l2', regularization_parameter=0.05, \n",
    "#               from_discrete=False, to_discrete=False).to(DEVICE)\n",
    "\n",
    "## In the case we use vectors, we are working in the discrete setting\n",
    "ot = NeuralOT(source_dual_net, target_dual_net, source_to_target_net, \n",
    "              regularization_mode='l2', regularization_parameter=0.05, \n",
    "              from_discrete=True, to_discrete=True).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plan_optimizer = Adam(ot.parameters(), lr=1e-3)\n",
    "# plan_scheduler = MultiStepLR(plan_optimizer, [20, 75])\n",
    "\n",
    "# # The training procedure is changed too\n",
    "plan_optimizer = Adam(ot.parameters(), lr=1.)\n",
    "plan_scheduler = MultiStepLR(plan_optimizer, [100, 400, 800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "losses = train(ot.plan_criterion, plan_optimizer, paired_loader, n_epochs=1000, device=DEVICE, \n",
    "               scheduler=plan_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_optimizer = Adam(ot.parameters(), lr=1e-4)\n",
    "mapping_scheduler = MultiStepLR(plan_optimizer, [100, 400, 800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_losses = train(ot.mapping_criterion, mapping_optimizer, paired_loader, n_epochs=500, device=DEVICE, \n",
    "                       scheduler=mapping_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mapping_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "idx = torch.multinomial(torch.ones(len(source)), n_samples)\n",
    "ot.eval().cpu()\n",
    "\n",
    "fig, axes = plt.subplots(2, n_samples, figsize=(20, 6))\n",
    "\n",
    "for i in range(n_samples):\n",
    "    img = source[idx[i]][0]\n",
    "    axes[0, i].imshow(img.squeeze(), cmap=\"Greys\")\n",
    "    axes[0, i].set_xticks([])\n",
    "    axes[0, i].set_yticks([])\n",
    "\n",
    "    mapped = ot.map(img.reshape(1, 1, h, w))\n",
    "    axes[1, i].imshow(mapped.squeeze().detach().numpy(), cmap=\"Greys\")\n",
    "    axes[1, i].set_xticks([])\n",
    "    axes[1, i].set_yticks([])\n",
    "    \n",
    "plt.tight_layout()\n",
    "fig.savefig(\"mappings.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_source, y_source = [], []\n",
    "for i in tqdm(range(len(source)), \"Source\"):\n",
    "    X, y = source[i]\n",
    "    X_source.append(X)\n",
    "    y_source.append(y)\n",
    "\n",
    "X_source = torch.cat(X_source).reshape(-1, h*w).numpy()\n",
    "y_source = np.array(y_source)\n",
    "\n",
    "X_target, y_target = [], []\n",
    "for i in tqdm(range(len(target)), \"Target\"):\n",
    "    X, y = target[i]\n",
    "    X_target.append(X)\n",
    "    y_target.append(y)\n",
    "\n",
    "X_target = torch.cat(X_target).reshape(-1, h*w).numpy()\n",
    "y_target = np.array(y_target)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "clf.fit(X_source, y_source)\n",
    "\n",
    "y_pred = clf.predict(X_target)\n",
    "print(\"1-KNN accuracy: {:.3f}\".format(accuracy_score(y_target, y_pred)))\n",
    "\n",
    "X_source_mapped, y_source_mapped = [], []\n",
    "for i in tqdm(range(len(source)), \"Source -> Target\"):\n",
    "    X, y = source[i]\n",
    "    mapped = ot.map(X.reshape(1, 1, h, w))\n",
    "    X_source_mapped.append(mapped.squeeze())\n",
    "    y_source_mapped.append(y)\n",
    "\n",
    "X_source_mapped = torch.cat(X_source_mapped).reshape(-1, h*w).detach().numpy()\n",
    "y_source_mapped = np.array(y_source_mapped)\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "clf.fit(X_source_mapped, y_source_mapped)\n",
    "\n",
    "y_pred = clf.predict(X_target)\n",
    "print(\"Mapped 1-KNN accuracy: {:.3f}\".format(accuracy_score(y_target, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ot, 'adaptation_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
