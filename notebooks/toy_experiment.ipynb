{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies\n",
    "First, you may need to install \n",
    "* NumPy - `pip install numpy`,\n",
    "* Matplotlib - `pip install matplotlib`,\n",
    "* PyTorch - `pip install torch torchvision`.\n",
    "\n",
    "Then you should be able to import all required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import MultiStepLR, ExponentialLR\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add parent directory to path to access sibling modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport neural_ot.data_loading, neural_ot.model, neural_ot.train\n",
    "from neural_ot.data_loading import ZipLoader, CircleDataset, CentersDataset, DistributionDataset\n",
    "from neural_ot.model import NeuralOT, Vector\n",
    "from neural_ot.train import train\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables\n",
    "First, we set `DEVICE` and `IS_CUDA` global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "    IS_CUDA = True\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    IS_CUDA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 1000\n",
    "BATCH_SIZE = 300\n",
    "N_BATCHES_PER_EPOCH = 10\n",
    "N_WORKERS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the dataloaders: `DistributionDataset` will sample normally distributed $2$D vectors and `CircleDataset` contains pre-generated samples from $9$ gaussians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distr = MultivariateNormal(torch.zeros(2), 0.4*torch.eye(2))\n",
    "distr_dset = DistributionDataset(distr)\n",
    "circle_dset = CircleDataset(N_SAMPLES, n_centers=9, sigma=0.08)\n",
    "\n",
    "# A dataset that consists only of the centers of the given gaussians \n",
    "# circle_dset = CentersDataset(9)\n",
    "\n",
    "gauss_loader = ZipLoader(distr_dset, circle_dset, batch_size=BATCH_SIZE,\n",
    "                         n_batches=N_BATCHES_PER_EPOCH, pin_memory=IS_CUDA, \n",
    "                         return_idx=True, num_workers=N_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(circle_dset.data[:, 0], circle_dset.data[:, 1], marker=\"+\", lw=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x_idx, x), (y_idx, y) in gauss_loader:\n",
    "    print(x_idx.shape, x.shape, y_idx.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We parametrized the $v$ function as neural network as it provided better performance in our setting. Nevertheless, one can use `Vector` to parametrize $v$. In this case don't forget to uncomment corresponding lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dual_net = nn.Sequential(nn.Linear(2, 200),\n",
    "                                nn.SELU(),\n",
    "                                nn.BatchNorm1d(200),\n",
    "                                nn.Linear(200, 500),\n",
    "                                nn.SELU(),\n",
    "                                nn.BatchNorm1d(500),\n",
    "                                nn.Linear(500, 1)\n",
    "                                )\n",
    "target_dual_net = Vector(initial=1e-2 * torch.randn(len(circle_dset)))\n",
    "# target_dual_net = nn.Sequential(nn.Linear(2, 200),\n",
    "#                                 nn.BatchNorm1d(200),\n",
    "#                                 nn.SELU(),\n",
    "#                                 nn.Linear(200, 500),\n",
    "#                                 nn.BatchNorm1d(500),\n",
    "#                                 nn.SELU(),\n",
    "#                                 nn.Linear(500, 500),\n",
    "#                                 nn.BatchNorm1d(500),\n",
    "#                                 nn.SELU(),\n",
    "#                                 nn.Linear(500, 1)\n",
    "#                                 )\n",
    "\n",
    "source_to_target_net = nn.Sequential(nn.Linear(2, 200),\n",
    "                                nn.SELU(),\n",
    "                                nn.BatchNorm1d(200),\n",
    "                                nn.Linear(200, 500),\n",
    "                                nn.SELU(),\n",
    "                                nn.BatchNorm1d(500),\n",
    "                                nn.Linear(500, 2)\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ot = torch.load('toy_model.pth')\n",
    "# ot = NeuralOT(source_dual_net, target_dual_net, source_to_target_net, \n",
    "#               regularization_mode='l2', regularization_parameter=0.05, \n",
    "#               from_discrete=False, to_discrete=False).to(DEVICE)\n",
    "\n",
    "## In the case we use vector, we are working in the discrete setting\n",
    "ot = NeuralOT(source_dual_net, target_dual_net, source_to_target_net, \n",
    "              regularization_mode='l2', regularization_parameter=5e-3, \n",
    "              from_discrete=False, to_discrete=True).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_optimizer = Adam(ot.parameters(), lr=1e-3)\n",
    "plan_scheduler = None #MultiStepLR(plan_optimizer, [5, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = train(ot.plan_criterion, plan_optimizer, gauss_loader, n_epochs=30, device=DEVICE, \n",
    "               scheduler=plan_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_optimizer = Adam(ot.parameters(), lr=1e-4)\n",
    "mapping_scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_losses = train(ot.mapping_criterion, mapping_optimizer, gauss_loader, n_epochs=100, device=DEVICE, \n",
    "                       scheduler=mapping_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mapping_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "fig, axes = plt.subplots(1, 4, figsize=(22, 5))\n",
    "\n",
    "n_points = 100000\n",
    "n_show = 500\n",
    "xmin, xmax = -1.5, 1.5\n",
    "ymin, ymax = -1.5, 1.5\n",
    "\n",
    "idx = np.random.choice(np.arange(n_points, dtype=np.int), n_show,\n",
    "                       replace=False)\n",
    "\n",
    "ax = axes[0]\n",
    "ps = distr.sample([n_points])\n",
    "with torch.no_grad():\n",
    "    ps_mapped = ot.cpu().map(ps).detach().numpy()\n",
    "ps = ps.numpy()\n",
    "H, xedges, yedges = np.histogram2d(ps[:, 0], ps[:, 1], \n",
    "                                   range=[[xmin, xmax], [ymin, ymax]])\n",
    "\n",
    "ax.contour(H.transpose(), extent=[xedges.min(), xedges.max(), \n",
    "                          yedges.min(), yedges.max()])\n",
    "sc = ax.scatter(circle_dset.data[:, 0], circle_dset.data[:, 1], \n",
    "           marker=\"+\", lw=0.6, label=\"Target dist.\")\n",
    "ax.set_title(\"Target and Source Distribution\")\n",
    "custom_lines = [sc, Line2D([0], [0], color=plt.cm.hsv(0.2), lw=2.)]\n",
    "ax.legend(custom_lines, [\"Target dist.\", \"Source dist.\"])\n",
    "\n",
    "xs = np.linspace(xmin, xmax, num=10)\n",
    "ys = np.linspace(ymin, ymax, num=10)\n",
    "\n",
    "ax = axes[1]\n",
    "XX, YY = np.meshgrid(xs, ys)\n",
    "XX = torch.tensor(XX.ravel(), dtype=torch.float)\n",
    "YY = torch.tensor(YY.ravel(), dtype=torch.float)\n",
    "\n",
    "X = torch.stack([XX, YY], dim=1)\n",
    "with torch.no_grad():\n",
    "    Z = ot.cpu().map(X).detach()\n",
    "offsets = Z - X \n",
    "\n",
    "ax.scatter(circle_dset.data[:, 0], circle_dset.data[:, 1], \n",
    "           marker=\"+\", lw=0.6)\n",
    "ax.quiver(XX, YY, offsets[:, 0], offsets[:, 1], angles=\"xy\", units=\"width\",\n",
    "          width=0.002)\n",
    "ax.set_title(\"Displacement Field\")\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "\n",
    "ax = axes[2]\n",
    "ax.set_title(\"Generated Samples\")\n",
    "ax.scatter(circle_dset.data[:, 0], circle_dset.data[:, 1], \n",
    "           marker=\"+\", lw=0.6, label=\"Target samples\")\n",
    "ax.scatter(ps_mapped[idx, 0], ps_mapped[idx, 1], \n",
    "           marker=\"+\", lw=0.6, label=\"Generated samples\")\n",
    "ax.legend()\n",
    "\n",
    "ax = axes[3]\n",
    "ax.set_title(\"Generated Density\")\n",
    "H, xedges, yedges = np.histogram2d(ps_mapped[:, 0], ps_mapped[:, 1], \n",
    "                                   range=[[xmin, xmax], [ymin, ymax]])\n",
    "\n",
    "ax.contour(H.transpose(), extent=[xedges.min(), xedges.max(), \n",
    "                          yedges.min(), yedges.max()])\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"gauss.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ot, 'toy_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
